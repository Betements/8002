{
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat_minor": 2,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Classes File",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "'''\nDo's\n- rehash WLS method as per paper description\n- LS plot looks off, scaling is wrong?\n- use PUMS data, i.e. large scale \n'''",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Local Import\n\nimport numpy as np\nimport pandas as pd\nimport math\nimport scipy.stats as ss\nimport numpy.linalg as la\nfrom itertools import product\nimport numpy.random as nr\n\n%cd '/home/nbuser/library/example_code_implementation_guide/'",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# R in Python Interface\nimport rpy2\nimport rpy2.robjects as ro\nfrom rpy2.robjects.packages import importr\nrobustbase = importr('robustbase')\nbase = importr('base')",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Plot Tools\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom matplotlib import cycler\ncolors = cycler('color', \n       ['#EE6666', '#3388BB', '#9988DD', '#EECC55', \n       '#88BB44', '#FFBBBB'])\n\nplt.rc('axes', facecolor='#E6E6E6', edgecolor='none',\n      axisbelow=True, grid=True, prop_cycle=colors)\nplt.rc('grid', color='w', linestyle='solid')\nplt.rc('xtick', direction='out', color='gray')\nplt.rc('ytick', direction='out', color='gray')\nplt.rc('patch', edgecolor='#E6E6E6')\nplt.rc('lines', linewidth=2)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Test Data - Census Tract\nstata = pd.read_stata('private_data_by_cells.dta')",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "data = stata[stata.columns[::-1]]",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# 1. Data Wrangle - Pandas to Numpy\nclass Wrangle:\n    '''\n    Data Wrangling Class'''\n    \n    def __init__(self, data, partition=None):\n        # Numpy-nize Census Tract\n        self.Key = data.keys()\n        Cell = np.unique(np.array(data[self.Key[0]])).astype(int)    \n        Y = [np.array(data.loc[data.loc[:, self.Key[0]]== i, self.Key[1]]) for i in Cell]\n        if len(self.Key) > 3:\n            None\n        else:\n            X = [np.array(data.loc[data.loc[:, self.Key[0]]== i, self.Key[2]]) for i in Cell]\n        \n        # optional partitioning\n        if partition is not None:\n            pX = [np.array_split(i, 2) for i in X]\n            pY = [np.array_split(i, 2) for i in Y]\n            if partition==1:\n                X = np.transpose(pX)[0]\n                Y = np.transpose(pY)[0]\n            elif partition==2:\n                X = np.transpose(pX)[1]\n                Y = np.transpose(pY)[1]\n\n        self.X = X\n        self.Y = Y \n        self.N = np.array([len(i) for i in X])\n        self.Cells = len(self.N) ",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class Alg_1:\n    '''\n    Chetty and Friedman Algorithm '''\n    \n    def __init__(self, data, method, figure=[], ϵ=4.0, partition=None):\n        ''' Setup selves '''\n        self.D = Wrangle(data, partition=partition)\n        self.col = len(self.D.Key) - 1\n        self.Outlier = np.array([list(i) for i in product([0, 1], repeat = self.col)])\n        self.figure = figure\n        self.method = method\n        self.ϵ = ϵ\n        self.nd75 = ss.norm.ppf(0.75)\n        self.W = np.array([1])\n        self.N = self.D.N\n        self.index = range(self.D.Cells)\n        self.range = range(0,4) \n    \n    def ω(self):\n        ''' Draws from Laplace Distribution '''\n        if self.method==\"OLS\":\n            return nr.laplace(0, 1/math.sqrt(2))\n        else:\n            return nr.laplace(0, 1/ϵ)\n    \n    def lsR(self, I, W=None, O=None):\n        ''' Least-squares Set up '''\n        if W is None:\n            W = self.W\n      \n        if O is None:\n            y = np.asarray(self.D.Y[I]) * np.sqrt(W)\n            x = np.asarray(self.D.X[I]) * np.sqrt(W)\n        else:\n            y = np.concatenate((self.D.Y[I], self.Outlier[O][0]), axis=None) * np.sqrt(W)\n            x = np.concatenate((self.D.X[I], self.Outlier[O][1]), axis=None) * np.sqrt(W)\n        \n        X = np.vstack([np.ones_like(x), x]).T\n        return X, y\n    \n    def lstsq(self, X, y, stderr=False):\n        betas = la.lstsq(X, y, rcond=None)[0]\n        residuals = y - np.dot(X, betas)\n        if stderr:\n            if len(y) > 5:\n                stderr = np.sqrt(residuals.dot(residuals) / np.sum(np.square(X.T[1] - np.mean(X.T[1]))) / (len(residuals) - self.col))\n            else:\n                stderr = np.inf\n        return betas, residuals, stderr\n    \n    def Scale(self, residuals, scale=None, w=None, c=4.685, K = 0.199):\n        ''' Scale calc as per S-Estimator '''\n        L = len(residuals)\n        if w is None:\n            scale = np.median(np.absolute(residuals - np.median(residuals))) / np.array([self.nd75])\n        else:\n            scale = np.sqrt((np.dot(w, np.square(residuals))) / np.array([L * K]))\n        \n        w = np.square(self.W - np.square(((residuals / L)<=c) / np.array([c])))\n        return scale, w\n    \n    def MM(self, I, O=None, stderr=False):\n        ''' MM - Estimator Regression '''\n        # Ordinary Least Squares\n        R01, R02 = self.lsR(I=I, O=O)\n        RO1, RO2, RO3 = self.lstsq(R01, R02)\n        S, W = self.Scale(RO2)\n        beta = RO1[1]\n        while True:\n            # WLR\n            R11, R12 = self.lsR(I=I, W=W, O=O)\n            RW1, RW2, RW3 = self.lstsq(R11, R12)\n            #7. Convergence\n            if math.isclose(RW1[1], beta):\n                break\n            else:\n                S, W = self.Scale(RW2, S, W)\n                beta = RW1[1]\n        # betas, residuals, stderr\n        if stderr:\n            RW1, RW2, RW3 = self.lstsq(R11, R12, True)\n        return RW1, RW2, RW3, S\n    \n    def lmrob(self, X, y, stderr=False):\n        '''\n        Run M-Estimator Robust Regression in R via rpy2\n        '''\n        # clear R workspace for looping\n        base.rm(list='ls()')\n        \n        # Set up formula environment\n        form = ro.Formula(\"y~x\")\n        form.environment[\"y\"] = ro.r['matrix'](ro.FloatVector(y.flatten()), ncol=1)\n        form.environment[\"x\"] = ro.r['matrix'](ro.FloatVector(X.T[1].flatten()), ncol=1)\n        \n        # Run Robust Regression\n        lmr = robustbase.lmrob(form)\n        \n        # must copy variables because of memory constraint\n        betas = np.array(lmr.rx2(\"coefficients\"), copy=True)\n        scale = np.array(lmr.rx2(\"scale\"), copy=True)\n        residuals = np.array(lmr.rx2(\"residuals\"), copy=True)\n        \n        if stderr:\n            if len(y) > 5:\n                stderr = np.sqrt(residuals.dot(residuals) / np.sum(np.square(X.T[1] - np.mean(X.T[1]))) / (len(residuals) - self.col))\n            else:\n                stderr = np.inf\n        \n        return betas, residuals, stderr, scale\n    \n    def oR(self, bool=False):\n        # Run every cellRegression in one line\n        if self.method == \"OLS\":\n            R0 = [self.lsR(i) for i in self.index]\n            self.RA = [self.lstsq(i[0], i[1], True) for i in R0]\n            R1 = [[self.lsR(i, O=j) for j in self.range] for i in self.index]\n            self.RB = [[self.lstsq(i[j][0], i[j][1]) for j in self.range] for i in R1]            \n        elif self.method == \"MM\":\n            self.RA = [self.MM(i, stderr=True) for i in self.index]\n            self.RB = [[self.MM(i, O=j) for j in self.range] for i in self.index]\n        elif self.method == \"LmRob\":\n            R0 = [self.lsR(i) for i in self.index]\n            self.RA = [self.lmrob(i[0], i[1], True) for i in R0]\n            R1 = [[self.lsR(i, O=j) for j in self.range] for i in self.index]\n            self.RB = [[self.lmrob(i[j][0], i[j][1]) for j in self.range] for i in R1]            \n            \n        if bool:\n            return np.transpose(self.RA)[0], np.transpose(self.RB)[0]\n        \n    def LSR(self):\n        self.oR()\n        # Return True Statistics\n        if \"F1\" or \"F2\" in self.figure:\n            LS = [[max([abs(self.RB[i][j][0][1] - self.RA[i][0][1]) for j in self.range]), \n                  np.argmax([abs(self.RB[i][j][0][1] - self.RA[i][0][1]) for j in self.range])]\n                  for i in self.index]\n            OSE = np.multiply(self.N, np.transpose(LS)[0])\n            MOSE = max(OSE)\n            if \"F1\" in self.figure:\n                self.MOSE = max(OSE) * 0.25\n                self.k = np.argmax(OSE)\n                self.j = np.transpose(LS)[1][self.k].astype(int)\n                self.cell = str(int(self.index[self.k]))\n                self.LS = np.transpose(LS)[0][self.k]\n            elif \"F2\" in self.figure:\n                self.fD = np.vstack((np.asarray(self.D.N), np.transpose(LS)[0]))\n                self.MOSE = MOSE\n        else:\n            MOSE = max(np.multiply(self.N, \n                [max([abs(self.RB[i][j][0][1] - self.RA[i][0][1]) for j in self.range]) for i in self.index]))\n        return np.transpose([[self.RA[i][j] for j in [0, 2]] for i in self.index]), MOSE\n    \n#     def LS(self):\n#         self.oR()\n        \n#         LS = [[max([abs(self.RB[i][j][0][1] - self.RA[i][0][1]) for j in self.range]), \n#                   np.argmax([abs(self.RB[i][j][0][1] - self.RA[i][0][1]) for j in self.range])]\n#                   for i in self.index]\n        \n#         OSE = np.multiply(self.N, np.transpose(LS)[0])\n        \n#         MOSE = max(OSE)\n\n#         return LS, OSE, MOSE\n    \n    def noise(self, θseθ, χ):\n        ''' Add Noise to Statistics '''\n        NN = np.asarray(self.D.N).astype(float)\n        S = NN * self.ϵ\n        noise = lambda x: x * math.sqrt(2)\n        \n        nθ = [i[1] for i in θseθ[0]] + χ * noise(self.ω()) / S\n        sen = np.square(θseθ[1]) + 2 * np.square(χ / S)\n        senθ = np.sqrt(sen.astype(float))\n        nsenθ = senθ + χ * noise(self.ω()) / S\n        nsenθ = np.asarray([\"Sample Size Too Small\" if i==np.inf else i for i in nsenθ])\n        nN = self.D.N * (1 + noise(self.ω()) / S)\n        return nθ, nsenθ, nN\n    \n    def __call__(self):\n        ''' Release Noise Infused Statistics '''\n        m1, m2 = self.LSR()\n        nθ, nsenθ, nN = self.noise(m1, m2)\n        return nθ, nsenθ, nN\n\n    def plot(self):\n        # run alg\n        self.LSR()\n        \n        fig, ax = plt.subplots(figsize = (8,6))\n        if \"F1\" in self.figure:\n            # Relevant Data\n            fD = np.vstack((self.D.X[self.k], self.D.Y[self.k]))\n            fo = np.vstack((self.Outlier[self.j][0], self.Outlier[self.j][1]))\n            fLA = lambda λ: self.RA[self.k][0][1]*λ + self.RA[self.k][0][0]\n            fLB = lambda λ: self.RB[self.k][self.j][0][1]*λ + self.RB[self.k][self.j][0][0]\n            \n            # Figure 1 - Effect of Outlier on Regression + MOSE line\n            ax.scatter(fD[0], fD[1])\n            ax.scatter(fo[0], fo[1])\n            l = np.linspace(0, 1, 5)\n            ax.plot(l, fLA(l), label=\"%s-Estimate in Actual Data\"%self.method)\n            ax.plot(l, fLB(l), linestyle = 'dashed', label=\"%s-Estimate with Outlier\"%self.method)\n            # LS line at 25th pctile\n            p25 = [0.25, 0.25]\n            yp25 = [fLA(p25[0]), fLB(p25[1])]\n            #ax.plot(p25, yp25, label=\"LS at 25th pctile = %s\"%str(self.MOSE))\n            \n            ax.set_title(\"FIGURE 1: Calculation of Local Sensitivity\", pad=35)\n            ax.set_ylabel(\"Child's Income Rank for cell = %s\"%self.cell)\n            ax.set_xlabel(\"Parent's Income Rank for cell = %s\"%self.cell)\n            \n            plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left',\n            ncol=2, mode=\"expand\", borderaxespad=0.)\n            ax.set_xlim(-0.025, 1.025)\n            ax.set_ylim(-0.025, 1.025)\n            \n        if \"F2\" in self.figure:\n            fLA = lambda λ: self.MOSE / λ\n            ax.scatter(self.fD[0], self.fD[1])\n            xmin = min(self.D.N)\n            xmax = max(self.D.N)\n            l = [xmin, xmax]\n            ax.plot(l, fLA(l), label=\"MOSE = $\\frac{χ}{N}=frac{%s}{N}$\"%str(self.MOSE))\n            ax.set_xscale('log')\n            ax.set_xlim(xmin *0.9, xmax * 1.1)\n            ax.set_ylim(-0.025, max(fLA(l))+0.5)\n            \n        #if kind == \"sdl\":\n            # Figure 3\n\n        ax.grid(which='minor', color='w', alpha=0.3)            \n        plt.show() ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "test = Alg_1(data, \"OLS\", figure=[])",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# %%timeit\n# Test = Alg_1(data, \"MM\", figure=[])\n# Test3 = Alg_1(data, \"LmRob\")\n# Test3()\n# A = Test.oR(True)\n# B = Test2.oR(True)\n# C = Test3.oR(True)\n# Index = range(10)\n# Range = range(4)\n# # R0 = [Test.lsR(i) for i in Index]\n# # RA = [Test.lmrob(i[0], i[1], True) for i in R0]\n# # R1 = [[Test.lsR(i, O=j) for j in Range] for i in Index]\n# # RB = [[Test.lmrob(i[j][0], i[j][1]) for j in Range] for i in R1]",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# LS line not correct\n# Not fitting data; test against scipy\n\nx0, y0 = Test.lsR(39)\na, b, c= Test.lstsq(x0, y0)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "v0 = ro.FloatVector(x0.T[1].flatten())\nv1 = ro.FloatVector(y0.flatten())\nm0 = ro.r['matrix'](v0, ncol=1)\nm1 = ro.r['matrix'](v1, ncol=1)\nform = ro.Formula(\"y~x\")\nform.environment[\"y\"] = m1\nform.environment[\"x\"] = m0\n\nlmr = robustbase.lmrob(form)\nβ = np.asarray(lmr.rx2(\"coefficients\"))\nσ = np.asarray(lmr.rx2(\"scale\"))\nresiduals = np.asarray(lmr.rx2(\"residuals\"))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "β",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "base.rm(list='ls()')",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "source": "\n\n\n\n\n\n\n\n\n\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "MSE = []\n\nfor i in range(1,11):\n    noise_θ = []\n    diff = []\n    \n    # But also, this needs to be done 500 times\n    for j in range(0,500):\n        # Draws random samples from Laplace or Normal:\n        ω = np.random.laplace(0, 1 / np.sqrt(2))\n        \n        # Noise infused Statistics\n        noise_θ = [a + np.sqrt(2) * (χ / (i * b)) * ω for (a, b) in zip(θ, N)]\n        diff.append(np.square(np.subtract(noise_θ, θ)))\n        \n    # Compute MSE\n    MSE.append(np.mean(diff))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Do's List'\n\nO. DWORK DP Algorithm\n\nA .SDL Techniques for Microdata\n - Local Suppresion\n - Uncorrelated Additive Noise - Pertubation Methods not differentially private\n    Z = X + ϵ\n   ϵᵢ ~ N(0, α * σᵢ^2)\n - Shuffling\n\n\nB. PUMS NY data at the 5% level from 2000 US Census\n - dumb regression model with molto numbers\n\nC. ways to compare methods\n - proximity to true values\n - reduce sensitivity ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# DWORK LEI ALGORITHM",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class Alg_2:\n    def __init__(self, ϵ=1):\n        pB1, pdB1 = Alg_1(data, \"MM\", ϵ=ϵ, partition=1).oR(True)\n        pB2, pdB2 = Alg_1(data, \"MM\", ϵ=ϵ, partition=2).oR(True)\n        self.B = np.stack((pB1, pB2)).T\n        self.dB =  np.stack((pdB1, pdB2)).T\n        self.n = 2 \n        self.Range = range(len(self.B))\n        self.ϵ = ϵ\n        self.base = 1 + 1 / np.log(self.n)\n\n    # omega (remove later)\n    def ω(self):\n        return nr.laplace(0, 1/self.ϵ)\n    \n    def iqr(self, x):\n        Q = np.asarray([[np.percentile(j, 75) - np.percentile(j, 25) for j in i] for i in x])\n        return Q\n         \n    def H(self, x=True):\n        if x:\n            iqr = self.iqr(self.B)\n            H = np.asarray([np.log(i) / np.log(self.base) for i in iqr])\n        else:\n            iqr = np.asarray([self.iqr(i) for i in self.dB])\n            H = np.asarray([np.log(i) / np.log(self.base) for i in np.transpose(iqr)])\n        return H\n    \n    def i(self):\n        return self.iqr(self.B)\n    \n    def S(self):\n        iqr = self.iqr(self.B)\n        H = self.H()\n        b = np.floor(H)\n        dH = self.H(False)\n        pb = np.asarray([np.logical_and(dH.T[i] >= b[i] - 0.5, \n                            dH.T[i] < b[i] + 1.5) for i in self.Range])\n        Bool = np.asarray([[np.all(pb[i].T[j]) for j in range(2)] for i in self.Range]) \n        s = np.asarray([[iqr[j] * self.base ** self.ω() if i[j] else None for j in range(2)] for i in Bool])\n        return s\n        \n    def h(self, s):\n        h = [[\n            1 / math.sqrt(len(D)) if i[j]==0 else i[j] / math.power(self.n, 0.25)\n        for j in self.Range] for i in s]\n        return h\n    \n#         Bool2 = [np.all(np.logical_and(np.greater_equal(dH[i], b[i] - 0.5), \n#                                       np.less(dH[i],b[i] + 0.5))) for i in self.Range]      ",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Test3 =Alg_2()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Test3.S()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "$\\,$",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def M(data, S, h=None, ϵ=4):\n    if h==None:\n        h = len(data) ** (- 1 / 3)\n    ω = np.random.laplace(0, S * h / ϵ)\n    return np.median(data) + ω\n\ndef RS(a, b, p=2, ϵ=4):\n    # partition algorithm\n    a_split = np.array_split(a, p)\n    b_split = np.array_split(b, p)\n    \n    # least squares β array\n    β = []\n    for j in np.arange(len(a_split)):\n        X = np.vstack([b_split[j], np.ones(len(b_split[j]))]).T\n        m, c = la.lstsq(A, a_split[j], rcond=None)[0]\n        β.append(m)\n        \n    # run M algorithm\n    return M(β, S(β))\n\ndef RH(a, b, p=2, ϵ=4):\n    # compute true β\n    θ = []\n    X = np.vstack([b, np.ones(len(b))]).T\n    m, c = la.lstsq(A, a, rcond=None)[0]\n    θ.append(m)\n    \n    # partition algorithm\n    a_split = np.array_split(a, p)\n    b_split = np.array_split(b, p)\n    \n    # least squares β array\n    β = []\n    for j in np.arange(len(a_split)):\n        X = np.vstack([b_split[j], np.ones(len(b_split[j]))]).T\n        m, c = la.lstsq(A, a_split[j], rcond=None)[0]\n        β.append(m)\n    \n    s = []\n    h = []\n    for j in len(a_split):\n        data = np.concatenate(S(a_split), S(b_split))\n        s.append(data)\n        h.append(S(a_split) / (len(a) ** (1 / (2 * len(a_split)))))\n    \n    return None",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "$\\,$\n\n$\\,$\n\n$\\,$\n\n$\\,$\n\n$\\,$\n\n$\\,$\n\n$\\,$",
      "metadata": {}
    }
  ]
}