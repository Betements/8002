{
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat_minor": 2,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Classes File",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "'''\nDo's\n- use PUMS data, i.e. large scale\n'''",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Local Import\nimport numpy as np\nimport pandas as pd\nimport math\nimport scipy.stats as ss\nimport numpy.linalg as la\nfrom itertools import product\nimport numpy.random as nr\n\n# Plot Tools\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom matplotlib import cycler\ncolors = cycler('color', \n       ['#EE6666', '#3388BB', '#9988DD', '#EECC55', \n       '#88BB44', '#FFBBBB'])\n\nplt.rc('axes', facecolor='#E6E6E6', edgecolor='none',\n      axisbelow=True, grid=True, prop_cycle=colors)\nplt.rc('grid', color='w', linestyle='solid')\nplt.rc('xtick', direction='out', color='gray')\nplt.rc('ytick', direction='out', color='gray')\nplt.rc('patch', edgecolor='#E6E6E6')\nplt.rc('lines', linewidth=2)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# R in Python Interface\nimport rpy2\nimport rpy2.robjects as ro\nfrom rpy2.robjects.packages import importr\nrobustbase = importr('robustbase')\nbase = importr('base')\nutils = importr('utils')",
      "metadata": {
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "source": "# For Rubenstein\nutils.install_packages('diffpriv')",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# url = 'https://github.com/Betements/8002/blob/master/private_data_by_cells.dta'\n# import requests\n# response = requests.get(url)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Test Data - Census Tract\n%cd '/home/nbuser/library/example_code_implementation_guide/'\nstata = pd.read_stata('private_data_by_cells.dta')\ndata = stata[stata.columns[::-1]]",
      "metadata": {
        "trusted": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "text": "/home/nbuser/library/example_code_implementation_guide\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# 1. Data Wrangle - Pandas to Numpy\nclass Wrangle:\n    '''\n    Data Wrangling Class'''\n    \n    def __init__(self, data, partition=None):\n        # Numpy-nize Census Tract\n        self.Key = data.keys()\n        Cell = np.unique(np.array(data[self.Key[0]])).astype(int)    \n        Y = [np.array(data.loc[data.loc[:, self.Key[0]]== i, self.Key[1]]) for i in Cell]\n        if len(self.Key) > 3:\n            None\n        else:\n            X = [np.array(data.loc[data.loc[:, self.Key[0]]== i, self.Key[2]]) for i in Cell]\n        \n        # optional partitioning\n        if partition is not None:\n            pX = [np.array_split(i, 2) for i in X]\n            pY = [np.array_split(i, 2) for i in Y]\n            if partition==1:\n                X = np.transpose(pX)[0]\n                Y = np.transpose(pY)[0]\n            elif partition==2:\n                X = np.transpose(pX)[1]\n                Y = np.transpose(pY)[1]\n\n        self.X = X\n        self.Y = Y \n        self.N = np.array([len(i) for i in X])\n        self.Cells = len(self.N) ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class Alg_1:\n    '''\n    Chetty and Friedman Algorithm \n    '''\n    def __init__(self, data, method, figure=[], ϵ=4.0, partition=None):\n        ''' Setup selves '''\n        self.D = Wrangle(data, partition=partition)\n        self.col = len(self.D.Key) - 1\n        self.Outlier = np.array([list(i) for i in product([0, 1], repeat = self.col)])\n        self.figure = figure\n        self.method = method\n        self.ϵ = ϵ\n        self.nd75 = ss.norm.ppf(0.75)\n        self.W = np.array([1])\n        self.N = self.D.N\n        self.index = range(self.D.Cells)\n        self.range = range(4) \n        if self.method == \"LmRob\":\n            self.form = ro.Formula(\"y~x\")\n    \n    def ω(self):\n        ''' \n        Draw from Laplace Distribution \n        '''\n#         if self.method==\"OLS\":\n#             return nr.laplace(0, 1/math.sqrt(2))\n#         else:\n#             return nr.laplace(0, 1/ϵ)\n        return nr.laplace(0, 1/math.sqrt(2))\n    \n    def r(self, x):\n         return range(len(x))\n    \n    def lsR(self, I, O=None):\n        ''' \n        Sort Arrays for Outlier Variations\n        '''\n        if O is None:\n            y = np.asarray(self.D.Y[I]) \n            x = np.asarray(self.D.X[I])\n        else:\n            y = np.block([self.D.Y[I], self.Outlier[O][0]])\n            x = np.block([self.D.X[I], self.Outlier[O][1]])\n\n        return x, y\n\n    def stack(self, x):\n        add = np.ones(len(x))\n        return np.block([[add], [x.T]]).T\n    \n    def lstsq(self, x, y, stderr=False, w=None):\n        '''\n        Calculus Linear Least Squares Optimisation via Numpy\n        '''\n        # Compare to Weight in LSTSQ\n        x = self.stack(x)\n        if w is not None:\n            XX = x.T.dot(np.diag(w)).T\n        else:\n            XX = x\n            \n        betas = np.dot(la.inv(XX.T.dot(x)), XX.T.dot(y))\n        ϵ = y - np.dot(XX, betas)\n        if stderr:\n            if len(y) > 5:\n                stderr = np.sqrt(ϵ.dot(ϵ) / np.sum(np.square(XX.T[1] - np.mean(XX.T[1]))) / (len(ϵ) - self.col))\n            else:\n                stderr = np.inf\n        return betas, ϵ, stderr\n    \n    def MAD(self, ϵ):\n        return np.median(np.absolute(ϵ - np.median(ϵ)))\n    \n    def Tukey(self, u, c=1.547):\n        ρ = np.power(u, 2) / 2 - np.power(u, 4) / (2 * math.pow(c, 2)) + np.power(u, 6) / (6 * math.pow(c, 4))\n        if np.any(np.abs(u) > c):\n            ρ[np.abs(u) > c] = math.pow(c, 2) / 6\n            \n        return ρ\n            \n    def Scale(self, ϵ, w=None, K=0.199):\n        ''' \n        Scale calculation for S-Estimator part of MM\n        '''\n        if w is None:\n            σ = self.MAD(ϵ) / self.nd75 \n        else:\n            σ = np.sqrt(np.sum(np.multiply(np.square(ϵ),w)) / (len(ϵ) * K))\n        \n        return σ\n    \n    def U(self, ϵ, σ):\n        return ϵ / σ\n    \n    def weight(self, u, method=\"S\", it=False):\n        if method==\"S\":\n            if not it:\n            # iteration = 1\n                W = np.square(u / 1.547)\n                if np.any(np.abs(u) > 1.547):\n                    W[np.abs(u) > 1.547] = 0\n                weight = np.square(1 - W)\n            else:\n                weight = self.Tukey(u) / np.square(u)\n        if method==\"MM\":\n            W = np.square(u / 4.685)\n            if np.any(np.abs(u) > 4.685):\n                W[np.abs(u) > 4.685] = 0\n            weight = np.square(1 - W)\n        \n        return weight\n    \n    def OLS(self, I, O=None, stderr=False):\n        # for bug testing\n        R01, R02 = self.lsR(I=I, O=O)\n        R, ϵ, boo = self.lstsq(R01, R02)\n        return R, ϵ, boo\n    \n    def MM(self, I, O=None, stderr=False):\n        ''' \n        MM - Estimator Regression Algorithm as specificied in S 2009\n        '''\n        # 1. Ordinary Least Squares\n        R01, R02 = self.lsR(I=I, O=O)\n        RO1, ϵ, boo = self.lstsq(R01, R02)\n        beta = RO1\n        # 2. S-Estimate Convergence\n        σ = self.Scale(ϵ)\n        U = self.U(ϵ, σ)\n        W = self.weight(U, \"S\", False)\n        S, ϵ, boo = self.lstsq(R01, R02, w=W)\n        # Convergence Loop\n        maxiter = 100\n        for i in range(maxiter):\n            σ = self.Scale(ϵ, w=W)\n            U = self.U(ϵ, σ)\n            W = self.weight(U, \"S\", True)\n            S, ϵ, boo = self.lstsq(R01, R02, w=W)\n            if np.allclose(S, beta, rtol=1e-09):\n                break\n            else:\n                beta = S\n        # use residuals and scale of S-estimate\n        # 3. MM-Estimate Convergence\n        σ = self.Scale(ϵ)\n        for i in range(maxiter):\n            U = self.U(ϵ, σ)\n            W = self.weight(U, \"MM\")\n            M, ϵ, boo = self.lstsq(R01, R02, w=W)\n            if np.allclose(M, beta, rtol=1e-03):\n                break\n            else:\n                beta = M\n#                 print(M)\n\n        if stderr:\n            RW1, RW2, boo = self.lstsq(R01, R02, True, w=W)\n        \n        # return betas, residuals, stderr, scale\n        return M, ϵ, boo, σ\n    \n    def lmrob(self, x, y):\n        '''\n        Run M-Estimator Robust Regression in R via rpy2\n        '''\n        # clear R workspace for looping\n        #base.rm(list='ls()')\n        # Set up formula environment\n        self.form.environment[\"y\"] = ro.r['matrix'](ro.FloatVector(y.flatten()), ncol=1)\n        self.form.environment[\"x\"] = ro.r['matrix'](ro.FloatVector(x.flatten()), ncol=1)\n        # Run Robust Regression\n        lmr = robustbase.lmrob(self.form, method = \"SMDM\", setting=\"KS2014\")\n        # must copy variables because of memory constraint\n        betas = np.array(lmr.rx2(\"coefficients\"), copy=True)\n        scale = np.array(lmr.rx2(\"scale\"), copy=True)\n        residuals = np.array(lmr.rx2(\"residuals\"), copy=True)\n        stderr = np.array(lmr.rx2(\"cov\"), copy=True)[0][0]\n        return betas, residuals, stderr, scale\n    \n    def oR(self, bool=False):\n        '''\n        Specify regression method and run all regression in one/two line(s)\n        '''\n        if self.method == \"OLS\":\n            R0 = np.asarray([self.lsR(i) for i in self.index])\n            self.RA = np.asarray([self.lstsq(i[0], i[1], True) for i in R0])\n            R1 = np.asarray([[self.lsR(i, O=j) for j in self.range] for i in self.index])\n            self.RB = np.asarray([[self.lstsq(i[j][0], i[j][1]) for j in self.range] for i in R1] )           \n        elif self.method == \"MM\":\n            self.RA = np.asarray([self.MM(i, stderr=True) for i in self.index])\n            self.RB = np.asarray([[self.MM(i, j) for j in self.range] for i in self.index])\n        elif self.method == \"LmRob\":\n            R0 = np.asarray([self.lsR(i) for i in self.index])\n            self.RA = np.asarray([self.lmrob(i[0], i[1]) for i in R0])\n            R1 = np.asarray([[self.lsR(i, O=j) for j in self.range] for i in self.index])\n            self.RB = np.asarray([[self.lmrob(i[j][0], i[j][1]) for j in self.range] for i in R1])          \n            \n        if bool:\n            return self.RA.T[0], self.RB.T[0]\n        \n    def LSR(self):\n        self.oR()\n        ''' \n        Calculate Local Sensitivity \n        '''\n        if \"F1\" or \"F2\" in self.figure:\n            LS = np.asarray([[max([abs(self.RB[i][j][0][1] - self.RA[i][0][1]) for j in self.range]), \n                  np.argmax([abs(self.RB[i][j][0][1] - self.RA[i][0][1]) for j in self.range])]\n                  for i in self.index])\n            OSE = np.multiply(self.N, np.transpose(LS)[0])\n            MOSE = max(OSE)\n            if \"F1\" in self.figure:\n                self.MOSE = np.around(max(LS.T[0] * 0.25), 3)\n                self.k = np.argmax(LS.T[0] * 0.25)\n                self.j = LS.T[1][self.k].astype(int)\n                self.cell = str(int(self.index[self.k]))\n            elif \"F2\" in self.figure:\n                self.fD = np.vstack((np.asarray(self.D.N), LS.T[0]))\n                self.MOSE = MOSE\n                self.LS = LS.T[0]\n                self.k = np.argmax(OSE)\n        else:\n            MOSE = max(np.multiply(self.N, \n                [max([abs(self.RB[i][j][0][1] - self.RA[i][0][1]) for j in self.range]) for i in self.index]))\n        return np.transpose([[self.RA[i][j] for j in [0, 2]] for i in self.index]), MOSE\n    \n    def noise(self, θseθ, χ):\n        ''' \n        Add Noise to Statistics \n        '''\n        NN = np.asarray(self.D.N).astype(float)\n        S = NN * self.ϵ\n        noise = lambda x: x * math.sqrt(2)\n        \n        nθ = [i[1] for i in θseθ[0]] + χ * noise(self.ω()) / S\n        sen = np.square(θseθ[1]) + 2 * np.square(χ / S)\n        senθ = np.sqrt(sen.astype(float))\n        nsenθ = senθ + χ * noise(self.ω()) / S\n        nsenθ = np.asarray([\"Sample Size Too Small\" if i==np.inf else i for i in nsenθ])\n        nN = self.D.N * (1 + noise(self.ω()) / S)\n        return nθ, nsenθ, nN\n    \n    def __call__(self):\n        ''' \n        Release Noise Infused Statistics \n        '''\n        m1, m2 = self.LSR()\n        nθ, nsenθ, nN = self.noise(m1, m2)\n        return nθ, nsenθ, nN\n    \n    def plot(self, I=None, O=None):\n        fig, ax = plt.subplots(figsize = (8,6))\n        if \"F1\" in self.figure:\n            self.LSR()\n            # Relevant Data\n            fD = np.vstack((self.D.X[self.k], self.D.Y[self.k]))\n            fo = np.vstack((self.Outlier[self.j][0], self.Outlier[self.j][1]))\n            fLA = lambda λ: self.RA[self.k][0][1]*λ + self.RA[self.k][0][0]\n            fLB = lambda λ: self.RB[self.k][self.j][0][1]*λ + self.RB[self.k][self.j][0][0]\n            \n            # Figure 1 - Effect of Outlier on Regression + MOSE line\n            ax.scatter(fD[0], fD[1])\n            ax.scatter(fo[0], fo[1])\n            l = np.linspace(0, 1, 5)\n            ax.plot(l, fLA(l), label=\"%s-Estimate in Actual Data\"%self.method)\n            ax.plot(l, fLB(l), linestyle = 'dashed', label=\"%s-Estimate with Outlier\"%self.method)\n            # LS line at 25th pctile\n            p25 = [0.25, 0.25]\n            yp25 = [fLA(p25[0]), fLB(p25[1])]\n            ax.plot(p25, yp25, color='black')\n            \n            ax.set_title(\"FIGURE 1: Calculation of Local Sensitivity $= %s$\"%str(self.MOSE), pad=35)\n            ax.set_ylabel(\"Child's Income Rank for Tract %s\"%self.cell)\n            ax.set_xlabel(\"Parent's Income Rank for Tract %s\"%self.cell)\n            \n            plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=2, mode=\"expand\", borderaxespad=0.)\n            ax.set_xlim(-0.025, 1.025)\n            ax.set_ylim(-0.025, 1.025)\n            \n        if \"F2\" in self.figure:\n            self.LSR()\n            fLA = lambda λ: self.MOSE / λ\n            ax.scatter(self.fD[0], self.fD[1])\n            xmin = min(self.D.N)\n            xmax = max(self.D.N)\n            l = [xmin, xmax]\n            ax.plot(l, fLA(l), label=\"$MOSE = χ\\,/\\,N = %s\\,/\\,N $\"%str(np.around(self.MOSE, 2)), color='black')\n            ax.scatter(self.fD[0][self.k], self.fD[1][self.k], label=\"Tract %d\"%self.k)\n            ax.set_title(\"FIGURE 2: Maximum Observed Sensitivity Envelope for %s\"%self.method, pad=35)\n            ax.set_ylabel(\"Local Sensitivity of $̂β_1$ Estimates\")\n            ax.set_xlabel(\"Number of Individuals in Tract\")\n            \n            ax.set_xscale('log')\n            ax.set_yscale('log')\n            \n            ax.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=2, mode=\"expand\", borderaxespad=0.)\n            ax.set_xlim(xmin *0.9, xmax * 1.1)\n            ax.set_ylim(min(self.LS)*0.9, self.MOSE/(xmin *0.9))\n            \n        if \"F3\" in self.figure:\n            # Figure 3\n            l = np.linspace(0, 1, 5)\n            if O is not None:\n                ax.scatter(self.Outlier[O][0], self.Outlier[O][1])\n                ao, bo = self.lsR(I, O)\n                if self.method == \"OLS\":\n                    co, do, eo = self.lstsq(ao, bo)\n                if self.method == \"MM\":\n                    co, do, eo, fo = self.MM(I, O)\n                if self.method == \"LmRob\":\n                    co, do, eo, fo = self.lmrob(ao, bo)\n                lineo = lambda x: co[1]*x + co[0]\n                ax.plot(l, lineo(l))\n            ax.scatter(self.D.X[I], self.D.Y[I])\n            a, b = self.lsR(I)\n            if self.method == \"OLS\":\n                c, d, e = self.lstsq(a, b)\n            if self.method == \"MM\":\n                c, d, e, f = self.MM(I)\n            if self.method == \"LmRob\":\n                c, d, e, f = self.lmrob(a, b)\n            line = lambda x: c[1]*x + c[0]\n            ax.plot(l, line(l))\n            ax.set_xlim(-0.025, 1.025)\n            ax.set_ylim(-0.025, 1.025)\n\n        ax.grid(which='minor', color='w', alpha=0.3)            \n        plt.savefig('fig.png')\n        plt.show()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "mmf1 = Alg_1(data, \"MM\", figure=[\"F1\"])\nolsf1 = Alg_1(data, \"OLS\", figure=[\"F1\"])\nRf1 = Alg_1(data, \"LmRob\", figure=[\"F1\"])\nmmf2 = Alg_1(data, \"MM\", figure=[\"F2\"])\nolsf2 = Alg_1(data, \"OLS\", figure=[\"F2\"])\nRf2 = Alg_1(data, \"LmRob\", figure=[\"F2\"])",
      "metadata": {
        "trusted": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ".plot()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "testmm.plot()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "testR.plot()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# %%timeit\n# Test = Alg_1(data, \"MM\", figure=[])\n# Test3 = Alg_1(data, \"LmRob\")\n# Test3()\n# A = Test.oR(True)\n# B = Test2.oR(True)\n# C = Test3.oR(True)\n# Index = range(10)\n# Range = range(4)\n# # R0 = [Test.lsR(i) for i in Index]\n# # RA = [Test.lmrob(i[0], i[1], True) for i in R0]\n# # R1 = [[Test.lsR(i, O=j) for j in Range] for i in Index]\n# # RB = [[Test.lmrob(i[j][0], i[j][1]) for j in Range] for i in R1]",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# LS line not correct\n# Not fitting data; test against scipy\n\nx0, y0 = Test.lsR(39)\na, b, c= Test.lstsq(x0, y0)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "MSE = []\n\nfor i in range(1,11):\n    noise_θ = []\n    diff = []\n    \n    # But also, this needs to be done 500 times\n    for j in range(0,500):\n        # Draws random samples from Laplace or Normal:\n        ω = np.random.laplace(0, 1 / np.sqrt(2))\n        \n        # Noise infused Statistics\n        noise_θ = [a + np.sqrt(2) * (χ / (i * b)) * ω for (a, b) in zip(θ, N)]\n        diff.append(np.square(np.subtract(noise_θ, θ)))\n        \n    # Compute MSE\n    MSE.append(np.mean(diff))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Do's List'\n\nO. DWORK DP Algorithm\n\nA .SDL Techniques for Microdata\n - Local Suppresion\n - Uncorrelated Additive Noise - Pertubation Methods not differentially private\n    Z = X + ϵ\n   ϵᵢ ~ N(0, α * σᵢ^2)\n - Shuffling\n\n\nB. PUMS NY data at the 5% level from 2000 US Census\n - dumb regression model with molto numbers\n\nC. ways to compare methods\n - proximity to true values\n - reduce sensitivity ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# DWORK LEI ALGORITHM",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class Alg_2:\n    def __init__(self, ϵ=1):\n        pB1, pdB1 = Alg_1(data, \"MM\", ϵ=ϵ, partition=1).oR(True)\n        pB2, pdB2 = Alg_1(data, \"MM\", ϵ=ϵ, partition=2).oR(True)\n        self.B = np.stack((pB1, pB2)).T\n        self.dB =  np.stack((pdB1, pdB2)).T\n        self.n = 2 \n        self.Range = range(len(self.B))\n        self.ϵ = ϵ\n        self.base = 1 + 1 / np.log(self.n)\n\n    # omega (remove later)\n    def ω(self):\n        return nr.laplace(0, 1/self.ϵ)\n    \n    def iqr(self, x):\n        Q = np.asarray([[np.percentile(j, 75) - np.percentile(j, 25) for j in i] for i in x])\n        return Q\n         \n    def H(self, x=True):\n        if x:\n            iqr = self.iqr(self.B)\n            H = np.asarray([np.log(i) / np.log(self.base) for i in iqr])\n        else:\n            iqr = np.asarray([self.iqr(i) for i in self.dB])\n            H = np.asarray([np.log(i) / np.log(self.base) for i in np.transpose(iqr)])\n        return H\n    \n    def i(self):\n        return self.iqr(self.B)\n    \n    def S(self):\n        iqr = self.iqr(self.B)\n        H = self.H()\n        b = np.floor(H)\n        dH = self.H(False)\n        pb = np.asarray([np.logical_and(dH.T[i] >= b[i] - 0.5, \n                            dH.T[i] < b[i] + 1.5) for i in self.Range])\n        Bool = np.asarray([[np.all(pb[i].T[j]) for j in range(2)] for i in self.Range]) \n        s = np.asarray([[iqr[j] * self.base ** self.ω() if i[j] else None for j in range(2)] for i in Bool])\n        return s\n        \n    def h(self, s):\n        h = [[\n            1 / math.sqrt(len(D)) if i[j]==0 else i[j] / math.power(self.n, 0.25)\n        for j in self.Range] for i in s]\n        return h\n    \n#         Bool2 = [np.all(np.logical_and(np.greater_equal(dH[i], b[i] - 0.5), \n#                                       np.less(dH[i],b[i] + 0.5))) for i in self.Range]      ",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Test3 =Alg_2()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Test3.S()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "$\\,$",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "### TREAT EACH CELL AS A SUBPARTITION",
      "metadata": {
        "trusted": true
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def M(data, S, h=None, ϵ=4):\n    if h==None:\n        h = len(data) ** (- 1 / 3)\n    ω = np.random.laplace(0, S * h / ϵ)\n    return np.median(data) + ω\n\ndef RS(a, b, p=2, ϵ=4):\n    # partition algorithm\n    a_split = np.array_split(a, p)\n    b_split = np.array_split(b, p)\n    \n    # least squares β array\n    β = []\n    for j in np.arange(len(a_split)):\n        X = np.vstack([b_split[j], np.ones(len(b_split[j]))]).T\n        m, c = la.lstsq(A, a_split[j], rcond=None)[0]\n        β.append(m)\n        \n    # run M algorithm\n    return M(β, S(β))\n\ndef RH(a, b, p=2, ϵ=4):\n    # compute true β\n    θ = []\n    X = np.vstack([b, np.ones(len(b))]).T\n    m, c = la.lstsq(A, a, rcond=None)[0]\n    θ.append(m)\n    \n    # partition algorithm\n    a_split = np.array_split(a, p)\n    b_split = np.array_split(b, p)\n    \n    # least squares β array\n    β = []\n    for j in np.arange(len(a_split)):\n        X = np.vstack([b_split[j], np.ones(len(b_split[j]))]).T\n        m, c = la.lstsq(A, a_split[j], rcond=None)[0]\n        β.append(m)\n    \n    s = []\n    h = []\n    for j in len(a_split):\n        data = np.concatenate(S(a_split), S(b_split))\n        s.append(data)\n        h.append(S(a_split) / (len(a) ** (1 / (2 * len(a_split)))))\n    \n    return None",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "$\\,$\n\n$\\,$\n\n$\\,$\n\n$\\,$\n\n$\\,$\n\n$\\,$\n\n$\\,$",
      "metadata": {}
    }
  ]
}