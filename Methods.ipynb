{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Classes File",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "code_folding": [],
        "ExecuteTime": {
          "start_time": "2019-10-16T22:18:15.521592Z",
          "end_time": "2019-10-16T22:18:15.566245Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Local Import\nimport numpy as np\nimport pandas as pd\nimport math\nimport scipy.stats as ss\nimport numpy.linalg as la\nfrom itertools import product\nimport numpy.random as nr\nimport pickle\n\n# Plot Tools\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom matplotlib import cycler\ncolors = cycler('color', \n       ['#EE6666', '#3388BB', '#9988DD', '#EECC55', \n       '#88BB44', '#FFBBBB'])\n\nplt.rc('axes', facecolor='#E6E6E6', edgecolor='none',\n      axisbelow=True, grid=True, prop_cycle=colors)\nplt.rc('grid', color='w', linestyle='solid')\nplt.rc('xtick', direction='out', color='gray')\nplt.rc('ytick', direction='out', color='gray')\nplt.rc('patch', edgecolor='#E6E6E6')\nplt.rc('lines', linewidth=2)",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-10-16T22:18:17.977Z",
          "end_time": "2019-10-16T22:18:25.967289Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "# R in Python Interface\nimport rpy2\nimport rpy2.robjects as ro\nfrom rpy2.robjects.packages import importr\nimport rpy2.robjects.numpy2ri as rnp\nrobustbase = importr('robustbase')\nbase = importr('base')\nutils = importr('utils')",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#diffpriv = importr('diffpriv')\n# Run this in an R console if it ever disappears\n# install.packages('diffpriv')\n# install.packages(\"devtools\")\n# devtools::install_github(\"brubinstein/diffpriv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "code_folding": []
      },
      "cell_type": "raw",
      "source": "# Test Data - Census Tract\n%cd '/home/nbuser/library/example_code_implementation_guide/'\nstata = pd.read_stata('private_data_by_cells.dta')\ndata = stata[stata.columns[::-1]]"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# OBJECTS",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def npl(x):\n    ''' Convert subarrays into lists \n    '''\n    return np.asarray([i.tolist() for i in x])",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class Wrangle:\n    ''' Data Wrangling Class for Test Data \n    '''\n    def __init__(self, data, aggregate=False):\n        ''' Numpy-nize Census Tract \n        '''\n        if 'PUMA5' in data:\n            data = data.drop(['PUMA5'], axis=1)\n        if data.keys()[0] != 'Cell':\n            data = data[data.columns[::-1]]\n        self.Key = data.keys()\n        if aggregate:\n            Y = np.asarray(data.loc[:, self.Key[1]])\n            X = np.asarray(data.loc[:, self.Key[2]])\n            self.N = len(X)\n        else:\n            if len(self.Key) > 3:\n                None\n            else:\n                Cell = np.unique(np.array(data[self.Key[0]])).astype(int)\n                Y = [np.asarray(data.loc[data.loc[:, self.Key[0]]== i, self.Key[1]]) for i in Cell]\n                X = [np.asarray(data.loc[data.loc[:, self.Key[0]]== i, self.Key[2]]) for i in Cell]\n                self.N = np.asarray([len(i) for i in X])\n        self.X = X\n        self.Y = Y \n        self.v = len(self.Key) - 1\n                \n    def __call__(self):\n        return self.X, self.Y, self.N, self.v",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class Methods:\n    ''' Class of regression methods and their parts\n    '''\n    def __init__(self, X, Y, N, v, method=[]):\n        ''' Make sure you are using at most 2-dimensional arrays for X, Y\n        '''\n        # We assume X is organised by index with dependent variables inside each\n        self.X = np.asarray(X)\n        self.Y = np.asarray(Y)\n        self.method = method\n        if \"SMDM\" in self.method:\n            self.form = ro.Formula(\"y~x\")\n        self.N = N\n        self.v = v\n        self.o = np.asarray([list(i) for i in product([0, 1], repeat = self.v)])\n        if type(self.N) is int:\n            self.index = [None]\n        else:\n            self.index = range(len(self.N))\n        self.range = range(4) \n        self.nd75 = ss.norm.ppf(0.75)\n        if \"Winsorize\" in self.method:\n            self.win = True\n        else:\n            self.win = False\n        if \"SE\" in self.method:\n            self.SE = True\n        else:\n            self.SE = False\n    \n    def sort(self, I=None, O=None, win=False):\n        ''' Sort arrays and append outlier variations\n        '''\n        if I is None:\n            y = self.Y\n            x = self.X\n        else:\n            y = self.Y[I]\n            x = self.X[I]\n        if O is not None:\n            y = np.block([y, self.o[O][0]])\n            x = np.block([x, self.o[O][1]])\n        if win:\n            x = ss.mstats.winsorize(x, limits=0.05)\n            x = x.filled()\n            y = ss.mstats.winsorize(y, limits=0.05)\n            y = y.filled()\n        return x, y\n    \n    def stack(self, x):\n        ''' Add constant to estimate \n        '''\n        return np.block([[np.ones(len(x))], [x.T]]).T\n    \n    def HCE(self, X, r, a):\n        ''' Calculate Heteroscedasticity-consistent standard errors\n        '''\n        HCE = np.dot(np.dot(a, X.T.dot(np.dot(np.diag(np.square(r)), X))), a)\n        return np.array(np.diag(HCE))\n    \n    def lstsq(self, x, y, w=None, se=False):\n        ''' Calculus linear least-squares\n        '''\n        x = self.stack(x)\n        if w is not None:\n            X = x.T.dot(np.diag(w)).T\n        else:\n            X = x\n        a = la.inv(X.T.dot(x))\n        β̂ = np.dot(a, X.T.dot(y))\n        r = y - np.dot(X, β̂)\n        if se:\n            se = self.HCE(X, r, a)\n            #se = np.sqrt(r.dot(r) / np.sum(np.square(X.T[1] - np.mean(X.T[1]))) / (len(r) - self.v))\n        return β̂, r, se\n\n    # OLS Method:\n    def OLS(self, I=None, O=None, se=False):\n        x, y = self.sort(I=I, O=O, win=self.win)\n        β̂, r, se = self.lstsq(x, y, None, se)\n        return β̂, r, se\n        \n    # MM Method:\n    def MAD(self, r):\n        ''' Median Absolute Deviation \n        '''\n        return np.median(np.absolute(r - np.median(r)))\n    \n    def Tukey(self, u, c=1.547):\n        ''' Tukey's biweight function ''' \n        ρ = np.power(u, 2) / 2 - np.power(u, 4) / (2 * math.pow(c, 2)) + np.power(u, 6) / (6 * math.pow(c, 4))\n        if np.any(np.abs(u) > c):\n            ρ[np.abs(u) > c] = math.pow(c, 2) / 6            \n        return ρ\n            \n    def σ(self, r, w=None, K=0.199):\n        ''' The scale for the S-Estimator we wish to minimize\n        '''\n        if w is None:\n            σ = self.MAD(r) / self.nd75 \n        else:\n            σ = np.sqrt(np.sum(np.multiply(np.square(r),w)) / (len(r) * K))\n        return σ\n    \n    def u(self, r, σ):\n        ''' Bisquare ratio \n        '''\n        return r / σ\n    \n    def weight(self, u, method=\"S\", it=False):\n        ''' Estimator Reweighing\n        '''\n        if method==\"S\":\n            if not it:\n            # iteration = 1\n                w = np.square(u / 1.547)\n                if np.any(np.abs(u) > 1.547):\n                    w[np.abs(u) > 1.547] = 0\n                weight = np.square(1 - w)\n            else:\n                weight = self.Tukey(u) / np.square(u)\n        if method==\"MM\":\n            w = np.square(u / 4.685)\n            if np.any(np.abs(u) > 4.685):\n                w[np.abs(u) > 4.685] = 0\n            weight = np.square(1 - w)\n        return weight\n\n    def MM(self, I=None, O=None, se=False, maxiter=100):\n        ''' MM-Estimator regression algorithm as specified in Susanti 2009\n        '''\n        x, y = self.sort(I, O, win=self.win)\n        β̂, r, se = self.lstsq(x, y, None, False)\n        # 2. S-Estimation\n        # 1st iteration\n        σ = self.σ(r)\n        u = self.u(r, σ)\n        w = self.weight(u, \"S\", False)\n        β̂, r, se = self.lstsq(x, y, w, False)\n        # IRWLS\n        for i in range(maxiter):\n            σ = self.σ(r, w)\n            u = self.u(r, σ)\n            w = self.weight(u, \"S\", True)\n            S, r, se = self.lstsq(x, y, w, False)\n            if np.allclose(S, β̂, rtol=1e-09):\n                break\n            else:\n                β̂ = S\n        # We use the MAD of the residuals of the S-estimator\n        σ = self.σ(r)\n        # 3. MM-Estimate Convergence \n        for i in range(maxiter):\n            u = self.u(r, σ)\n            w = self.weight(u, \"MM\")\n            M, r, se = self.lstsq(x, y, w, False)\n            if np.allclose(M, β̂, rtol=1e-03):\n                break\n            else:\n                β̂ = M\n        if se:\n            β̂s, rs, se = self.lstsq(x, y, w, True)\n        return M, r, se, σ   \n        \n    # SMDM Method:\n    def SMDM(self, I=None, O=None):\n        ''' Run SMDM from R's 'lmrob' package via rpy2\n        '''\n        x, y = self.sort(I, O, win=self.win)\n        try:\n            nr, nc = x.shape\n        except:\n            nr = x.shape[0]\n            nc = 1\n        # Set up formula environment\n        rnp.activate()\n        form.environment[\"y\"] = ro.r['matrix'](y, nrow=nr, ncol=1)\n        form.environment[\"x\"] = ro.r['matrix'](x, nrow=nr, ncol=nc)\n        # Run Robust Regression\n        lmr = robustbase.lmrob(self.form, method = \"SMDM\", setting=\"KS2014\")\n        # must copy variables because of memory constraint\n        betas = np.array(lmr.rx2(\"coefficients\"), copy=True)\n        scale = np.array(lmr.rx2(\"scale\"), copy=True)\n        residuals = np.array(lmr.rx2(\"residuals\"), copy=True)\n        stderr = np.array(np.diag(lmr.rx2(\"cov\")), copy=True)\n        return betas, residuals, stderr, scale\n    \n    def __call__(self, withoutliers=True):\n        ''' Specify regression method and run all regression in one/two line(s)\n        '''\n        if \"OLS\" in self.method:\n            if self.index is None:\n                regression = self.OLS(None, None, self.SE)\n                if withoutliers:\n                    withoutliers = np.asarray([self.OLS(None, O, self.SE) for O in self.range])\n            else:\n                regression = np.asarray([self.OLS(I, None, self.SE) for I in self.index])\n                if withoutliers:\n                    withoutliers = np.asarray([[self.OLS(I, O, self.SE) for O in self.range] for I in self.index])    \n        elif \"MM\" in self.method:\n            if self.index is None:\n                regression = self.MM(None, None, self.SE, 100)\n                if withoutliers:\n                    withoutliers = np.asarray([self.MM(None, O, self.SE) for O in self.range])\n            else:\n                regression = np.asarray([self.MM(I, None, self.SE) for I in self.index])\n                if withoutliers:\n                    withoutliers = np.asarray([[self.MM(I, O, self.SE) for O in self.range] for I in self.index])\n        elif \"SMDM\" in self.method:\n            if self.index is None:\n                regression = self.SMDM(None, None)\n                if withoutliers:\n                    withoutliers = np.asarray([self.SMDM(None, O) for O in self.range])\n            else:\n                regression = np.asarray([self.SMDM(I, None) for I in self.index])\n                if withoutliers:\n                    withoutliers = np.asarray([[self.MM(I, O) for O in self.range] for I in self.index])\n        return regression, withoutliers",
      "execution_count": 59,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class LocSnoises:\n    ''' Release Algorithm by Chetty & Friedman\n    '''\n    def __init__(self, regression, withoutliers, N, method=[\"Laplace\"]):\n        self.RA = regression\n        self.RB = withoutliers\n        self.range = range(4)\n        self.N = N\n        if type(self.N) is int:\n            self.index = [None]\n        else:\n            self.index = range(len(self.N))\n        self.method = method\n            \n    def ω(self):\n        ''' Draws from Laplace or Normal Distribution \n        '''\n        if \"Laplace\" in self.method:\n            return nr.laplace(0, 1/math.sqrt(2))\n        elif \"Gaussian\" in self.method:\n            return nr.normal(0, math.sqrt(1/math.sqrt(2)))\n    \n    def LS(self):\n        ''' Calculate Local Sensitivity \n        '''\n        MOSE = max(np.multiply(self.N, \n                [max([abs(self.RB[i][j][0][1] - self.RA[i][0][1]) for j in self.range]) for i in self.index]))\n        return np.transpose([[self.RA[i][j] for j in [0, 2]] for i in self.index]), MOSE\n    \n    def noise(self, θseθ, χ):\n        ''' Add Noise to Statistics \n        '''\n        NN = np.asarray(self.N).astype(float)\n        S = NN * self.ϵ\n        noise = lambda x: x * math.sqrt(2)\n        \n        nθ = [i[1] for i in θseθ[0]] + χ * noise(self.ω()) / S\n        sen = np.square(θseθ[1]) + 2 * np.square(χ / S)\n        senθ = np.sqrt(sen.astype(float))\n        nsenθ = senθ + χ * noise(self.ω()) / S\n        nsenθ = np.asarray([\"Sample Size Too Small\" if i==np.inf else i for i in nsenθ])\n        nN = self.N * (1 + noise(self.ω()) / S)\n        return nθ, nsenθ, nN\n\n    def MSE(self, θ):\n        MSE = []\n        for i in range(1,11):\n            noise_θ = []\n            diff = []\n\n            # But also, this needs to be done 500 times\n            for j in range(0,500):\n                # Draws random samples from Laplace or Normal:\n                ω = np.random.laplace(0, 1 / np.sqrt(2))\n\n                # Noise infused Statistics\n                noise_θ = [a + np.sqrt(2) * (χ / (i * b)) * ω for (a, b) in zip(θ, N)]\n                diff.append(np.square(np.subtract(noise_θ, θ)))\n\n            # Compute MSE\n            return MSE.append(np.mean(diff))\n\n    def __call__(self):\n        ''' Release Noise Infused Statistics \n        '''\n        m1, m2 = self.LS()\n        nθ, nsenθ, nN = self.noise(m1, m2)\n        return nθ, nsenθ, nN",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "raw",
      "source": "Note for DWORK:\n''' We have assumed aggregate data instead of tract partitioning\n            Since we have access to only a 5% sample of any Census\n            ### b is org by cells with b's in cols\n            ### B.T is B0,B1 arrays\n            ### db is org by cell with alt's within - 3dim\n            ### dB.T splits B_0 and B_1 alts into two arrays with 4 subarrys each '''"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class DWORK:\n    def __init__(self, Tr, r, o, ϵ, psize, method=[\"Laplace\"]):\n        ''' Dwork & Lei Release Algorithm\n            Developed for releasing true β w/ noise\n            Can be used for releasing SE's as well\n        '''\n        # length of each cell\n        self.n = psize\n        # base for each cell (for S algorithm)\n        self.base = np.asarray([1 + 1 / np.log(i) for i in self.n])\n        \n        # store β̂'s and β̂ᵢ's:\n        self.Tb = Tr[0][0][0]\n        self.b = npl(r.T[0]).T\n        self.db = npl(o.T[0].T)\n        \n        # number of partitions & range\n        p = len(self.b.T)\n        self.range = range(p)\n        # total sample size\n        self.N = len(Tr[0][0][1])\n        self.ϵ = ϵ\n        # define delta parameter\n        ndivp = self.N / p\n        self.δ = 0.5 * math.pow(ndivp, (- ϵ) * math.log(ndivp))\n        \n        self.method = method\n    \n    def ω(self, h=1):\n        ''' Laplace of Gaussian Mechanism\n        '''\n        if \"Laplace\" in self.method:\n            return nr.laplace(0, h/self.ϵ)\n        elif \"Gaussian\" in self.method:\n            return math.sqrt(h * math.sqrt(2 * math.log(1.25 / self.δ)) / self.ϵ)\n        else:\n            raise ValueError('No Mechanism Specified')\n    \n    # 2. Run S algorithm\n    def IQR(self, b, db=None):\n        ''' Function: Interquartile Range of partitioned β̂'s\n        '''\n        if db is not None:\n            # Array like O array but with iqr calc for switching old β with new β\n            nb = np.asarray([[np.block([[np.delete(b.T, i, 0)], [db[i][j]]]) for j in range(4)] for i in self.range])\n            IQR = np.asarray([[[np.percentile(k, 75) - np.percentile(k, 25) for k in i.T] for i in j]for j in nb])\n        else:\n            # Original IQR for β\n            IQR = np.asarray([np.percentile(i, 75) - np.percentile(i, 25) for i in b])\n        return IQR\n    \n    def H(self, o=False):\n        ''' Part 1: H\n            - Compute H for each β̂ and compute H' for alt β̂'s'\n        '''\n        if o:\n            IQR = self.IQR(self.b, self.db)\n            H = np.asarray([[np.log(IQR[i][j]) / np.log(self.base[i]) for j in range(4)]                          \n                           for i in self.range])\n        else:\n            IQR = self.IQR(self.b)\n            H = np.asarray([np.log(IQR) / np.log(self.base[i]) for i in self.range])\n        return H\n    \n    def S(self, BOOL=False):\n        ''' Part 2: S Algorithm\n            - Compute Noise-infused SCALE for β̂'s\n        '''\n        H = self.H()\n        dH = self.H(True)\n        # 2.3 compute bins for each H\n        bins = np.asarray([[np.abs(H[i] - dH[i][j] + self.ω()) for j in range(4)] for i in self.range])\n        # 2.4 return TRUE for violation of 2.3 <= 1\n        booL = np.asarray([np.all(i > 1) for i in bins])\n        # [optional] for seeing which cells fail\n        if BOOL:\n            return booL\n        else:\n            s = np.asarray([self.IQR(self.b) * self.base[i] ** self.ω() for i in self.range])\n            s[booL] = np.inf\n            return s\n\n    # 3. compute h for each s\n    def h(self, s):\n        h = np.asarray([i / math.pow(self.N, 0.25) for i in s])\n        h[h==0] = 1 / math.sqrt(self.N)\n        h[h==np.inf] = 0\n        return h\n    \n    def z(self, h):\n        return np.asarray([\n            self.ω(i) for i in h])\n    \n    def RH(self, s, BOOL=False):\n        ''' Part 3: Release\n            - Compute True β + Noise\n        '''\n        h = self.h(s)\n        # 3.1 np.abs(alt β̂'s - β̂) <= h array\n        bins = np.asarray([[np.abs(self.b.T[i] - self.db[i][j]) for j in range(4)] for i in self.range])\n        booL = np.asarray([[bins[i][j] > h[i] for j in range(4)] for i in self.range])\n        # return True for violation\n        anybooL = np.asarray([not np.any([not np.any(booL[i][j]) for j in range(4)]) for i in self.range])\n        # 3.2 for TRUE compute β + noise\n        RHb = self.Tb + self.z(h)\n        RHb[anybooL] = None\n        # [optional] for seeing which cells fail\n        if BOOL:\n            return anybooL\n        else:\n            try:\n                # 3.3 find min(β + noise)\n                np.nanmin(RHb, 0)\n                return np.nanmin(RHb, 0)\n            except:\n                return None\n            \n    def __call__(self, BOOL=False):\n        ''' Set up so one can return Boolean Arrays for both S and RH algorithm \n        '''\n        if BOOL:\n            s = self.S()\n            RH = self.RH(s, BOOL)\n            S = self.S(BOOL)\n            return S, RH\n        else:\n            s = self.S()\n            RH = self.RH(s, BOOL)\n            if RH is None:\n                return \"Too Sensitive\"\n            else:\n                return s, RH",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class MSE:\n    ''' We compute MSE's for the DWORK algorithm outputs for different epsilons\n    '''\n    def __init__(self, Tr, r, o, psize, method=[\"Laplace\"]):    \n        self.T = Tr[0][0][0]\n        self.Tr = Tr\n        self.r = r\n        self.o = o\n        self.psize = psize\n        self.method = method\n        \n    def __call__(self):\n        self.MSE = []\n        for ϵ in range(1,11):\n            diff = []\n            # We repeat DWORK 20 times\n            for j in range(0,20):\n                s, noise = DWORK(self.Tr, self.r, self.o, ϵ, self.psize, self.method)\n                try:\n                    diff.append(np.square(np.subtract(noise, self.T)))\n                except:\n                    pass\n            # Compute MSE\n        return self.MSE.append(np.mean(diff))\n    ",
      "execution_count": 69,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Tests and Data Storage",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Test 1 Using Alaska V v. H\n%cd /home/nbuser/library/DP/Data/\nwith open(\"Alaska_VH.pickle\", \"rb\") as handle:\n    VH = pickle.load(handle)\nwith open(\"Alaska_VH.pickle\", \"rb\") as handle:\n    YA = pickle.load(handle)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/library/DP/Data\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "VH101 = Wrangle(VH.get_group(101))\nvh101X, vh101Y, vh101N, vh101v = VH101()\nVHOLS = Methods(vh101X, vh101Y, vh101N, vh101v, [\"OLS\", \"Winsorize\", \"SE\"])",
      "execution_count": 63,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Or = VHOLS(False)",
      "execution_count": 65,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x, y, n, v = Wrangle(data)()\nhey = Methods(x, y, n, v, \"OLS\")\nQ0, Q1 = hey.sort(0)\nQ2, Q3 = hey.winsorize(Q0, Q1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "XX, YY, NN, vv = Wrangle(data, aggregate=True)()\nX, Y, N, v = Wrangle(data)()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "OLSA = Methods(XX, YY, NN, vv, \"OLS\")\nOLSP = Methods(X, Y, N, v, \"OLS\")\n\nMMA = Methods(XX, YY, NN, vv, \"MM\")\nMMP = Methods(X, Y, N, v, \"MM\")\n\nSMDMA = Methods(XX, YY, NN, vv, \"SMDM\")\nSMDMP = Methods(X, Y, N, v, \"SMDM\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# 0. calc true statistic (aggregate level)\n# 1. store partition stats (cell/tract level)\nOTr = np.asarray(OLSA(withoutliers=False))\nOr, Oo = OLSP()\nOpsize = OLSP.N\n\nMTr = np.asarray(MMA(withoutliers=False))\nMr, Mo = MMP()\nMpsize = mP.N\n\nSTr = np.asarray(SMDMA(withoutliers=False))\nSr, So = SMDMP()\nSpsize = SMDMP.N",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#pickle.dump([OTr, Or, Oo, Opsize, MTr, Mr, Mo, Mpsize, STr, Sr, So, Spsize], open(\"trial.p\", \"wb\"))\n# a1, b1, c1, d1, a2, b2, c2, d2, c3, b3, c3, d3  = pickle.load(open(\"trial.p\",\"rb\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "OLSDWORK = DWORK(OTr, Or, Oo, 4, Opsize)\nMMDWORK = DWORK(MTr, Mr, Mo, 4, Mpsize)\nSMDMDWORK = DWORK(STr, Sr, So, 4, Spsize)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "OD = OLSDWORK()\nOB = OLSDWORK(True)\nMD = MMDWORK()\nMB = MMDWORK(True)\nSD = SMDMDWORK()\nSB = SMDMDWORK(True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Timeit MM v SMDM",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "t = OTr[0][0][0]\nprint(abs(t - OD))\nprint(abs(t - MD))\nprint(abs(t - SD))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(np.sum(OB[0]), np.sum(OB[1]))\nprint(np.sum(MB[0]), np.sum(MB[1]))\nprint(np.sum(SB[0]), np.sum(SB[1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "raw",
      "source": "\n\n\n\n\n\n\n\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "raw",
      "source": "class Alg_1:\n    '''\n    Chetty and Friedman Algorithm w/ Cell partition\n    '''\n    def __init__(self, data, method, figure=[], ϵ=4.0):\n        ''' Setup selves '''\n        self.D = Wrangle(data)\n        self.col = len(self.D.Key) - 1\n        self.Outlier = np.array([list(i) for i in product([0, 1], repeat = self.col)])\n        self.figure = figure\n        self.method = method\n        self.ϵ = ϵ\n        self.nd75 = ss.norm.ppf(0.75)\n        self.W = np.array([1])\n        self.N = self.D.N\n        self.index = range(self.D.Cells)\n        self.range = range(4) \n        if self.method == \"LmRob\":\n            self.form = ro.Formula(\"y~x\")\n    \n    def ω(self):\n        ''' \n        Draw from Laplace Distribution \n        '''\n        if \"Dwork\" in self.figure:\n            return nr.laplace(0, 1/ϵ)\n        else:\n            return nr.laplace(0, 1/math.sqrt(2))\n    \n    def r(self, x):\n         return range(len(x))\n    \n    def lsR(self, I, O=None):\n        ''' \n        Sort Arrays for Outlier Variations\n        '''\n        if O is None:\n            y = np.asarray(self.D.Y[I]) \n            x = np.asarray(self.D.X[I])\n        else:\n            y = np.block([self.D.Y[I], self.Outlier[O][0]])\n            x = np.block([self.D.X[I], self.Outlier[O][1]])\n\n        return x, y\n\n    def stack(self, x):\n        add = np.ones(len(x))\n        return np.block([[add], [x.T]]).T\n    \n    def lstsq(self, x, y, stderr=False, w=None):\n        '''\n        Calculus Linear Least Squares Optimisation via Numpy\n        '''\n        # Compare to Weight in LSTSQ\n        x = self.stack(x)\n        if w is not None:\n            XX = x.T.dot(np.diag(w)).T\n        else:\n            XX = x\n            \n        betas = np.dot(la.inv(XX.T.dot(x)), XX.T.dot(y))\n        ϵ = y - np.dot(XX, betas)\n        if stderr:\n            if len(y) > 5:\n                stderr = np.sqrt(ϵ.dot(ϵ) / np.sum(np.square(XX.T[1] - np.mean(XX.T[1]))) / (len(ϵ) - self.col))\n            else:\n                stderr = np.inf\n        return betas, ϵ, stderr\n    \n    def MAD(self, ϵ):\n        return np.median(np.absolute(ϵ - np.median(ϵ)))\n    \n    def Tukey(self, u, c=1.547):\n        ρ = np.power(u, 2) / 2 - np.power(u, 4) / (2 * math.pow(c, 2)) + np.power(u, 6) / (6 * math.pow(c, 4))\n        if np.any(np.abs(u) > c):\n            ρ[np.abs(u) > c] = math.pow(c, 2) / 6\n            \n        return ρ\n            \n    def Scale(self, ϵ, w=None, K=0.199):\n        ''' \n        Scale calculation for S-Estimator part of MM\n        '''\n        if w is None:\n            σ = self.MAD(ϵ) / self.nd75 \n        else:\n            σ = np.sqrt(np.sum(np.multiply(np.square(ϵ),w)) / (len(ϵ) * K))\n        \n        return σ\n    \n    def U(self, ϵ, σ):\n        return ϵ / σ\n    \n    def weight(self, u, method=\"S\", it=False):\n        if method==\"S\":\n            if not it:\n            # iteration = 1\n                W = np.square(u / 1.547)\n                if np.any(np.abs(u) > 1.547):\n                    W[np.abs(u) > 1.547] = 0\n                weight = np.square(1 - W)\n            else:\n                weight = self.Tukey(u) / np.square(u)\n        if method==\"MM\":\n            W = np.square(u / 4.685)\n            if np.any(np.abs(u) > 4.685):\n                W[np.abs(u) > 4.685] = 0\n            weight = np.square(1 - W)\n        \n        return weight\n    \n    def OLS(self, I, O=None, stderr=False):\n        # for bug testing\n        R01, R02 = self.lsR(I=I, O=O)\n        R, ϵ, boo = self.lstsq(R01, R02)\n        return R, ϵ, boo\n    \n    def MM(self, I, O=None, stderr=False):\n        ''' \n        MM - Estimator Regression Algorithm as specificied in S 2009\n        '''\n        # 1. Ordinary Least Squares\n        R01, R02 = self.lsR(I=I, O=O)\n        RO1, ϵ, boo = self.lstsq(R01, R02)\n        beta = RO1\n        # 2. S-Estimate Convergence\n        σ = self.Scale(ϵ)\n        U = self.U(ϵ, σ)\n        W = self.weight(U, \"S\", False)\n        S, ϵ, boo = self.lstsq(R01, R02, w=W)\n        # Convergence Loop\n        maxiter = 100\n        for i in range(maxiter):\n            σ = self.Scale(ϵ, w=W)\n            U = self.U(ϵ, σ)\n            W = self.weight(U, \"S\", True)\n            S, ϵ, boo = self.lstsq(R01, R02, w=W)\n            if np.allclose(S, beta, rtol=1e-09):\n                break\n            else:\n                beta = S\n        # use residuals and scale of S-estimate\n        # 3. MM-Estimate Convergence\n        σ = self.Scale(ϵ)\n        for i in range(maxiter):\n            U = self.U(ϵ, σ)\n            W = self.weight(U, \"MM\")\n            M, ϵ, boo = self.lstsq(R01, R02, w=W)\n            if np.allclose(M, beta, rtol=1e-03):\n                break\n            else:\n                beta = M\n\n        if stderr:\n            RW1, RW2, boo = self.lstsq(R01, R02, True, w=W)\n        \n        # return betas, residuals, stderr, scale\n        return M, ϵ, boo, σ\n    \n    def lmrob(self, x, y):\n        '''\n        Run M-Estimator Robust Regression in R via rpy2\n        '''\n        # clear R workspace for looping\n        #base.rm(list='ls()')\n        # Set up formula environment\n        self.form.environment[\"y\"] = ro.r['matrix'](ro.FloatVector(y.flatten()), ncol=1)\n        self.form.environment[\"x\"] = ro.r['matrix'](ro.FloatVector(x.flatten()), ncol=1)\n        # Run Robust Regression\n        lmr = robustbase.lmrob(self.form, method = \"SMDM\", setting=\"KS2014\")\n        # must copy variables because of memory constraint\n        betas = np.array(lmr.rx2(\"coefficients\"), copy=True)\n        scale = np.array(lmr.rx2(\"scale\"), copy=True)\n        residuals = np.array(lmr.rx2(\"residuals\"), copy=True)\n        stderr = np.array(lmr.rx2(\"cov\"), copy=True)[0][0]\n        return betas, residuals, stderr, scale\n    \n    def oR(self, bool=False):\n        '''\n        Specify regression method and run all regression in one/two line(s)\n        '''\n        if self.method == \"OLS\":\n            R0 = np.asarray([self.lsR(i) for i in self.index])\n            self.RA = np.asarray([self.lstsq(i[0], i[1], True) for i in R0])\n            R1 = np.asarray([[self.lsR(i, O=j) for j in self.range] for i in self.index])\n            self.RB = np.asarray([[self.lstsq(i[j][0], i[j][1]) for j in self.range] for i in R1] )           \n        elif self.method == \"MM\":\n            self.RA = np.asarray([self.MM(i, stderr=True) for i in self.index])\n            self.RB = np.asarray([[self.MM(i, j) for j in self.range] for i in self.index])\n        elif self.method == \"LmRob\":\n            R0 = np.asarray([self.lsR(i) for i in self.index])\n            self.RA = np.asarray([self.lmrob(i[0], i[1]) for i in R0])\n            R1 = np.asarray([[self.lsR(i, O=j) for j in self.range] for i in self.index])\n            self.RB = np.asarray([[self.lmrob(i[j][0], i[j][1]) for j in self.range] for i in R1])          \n            \n        if bool:\n            return self.RA.T[0], self.RB.T[0]\n        \n    def LSR(self):\n        self.oR()\n        ''' \n        Calculate Local Sensitivity \n        '''\n        if \"F1\" or \"F2\" in self.figure:\n            LS = np.asarray([[max([abs(self.RB[i][j][0][1] - self.RA[i][0][1]) for j in self.range]), \n                  np.argmax([abs(self.RB[i][j][0][1] - self.RA[i][0][1]) for j in self.range])]\n                  for i in self.index])\n            OSE = np.multiply(self.N, np.transpose(LS)[0])\n            MOSE = max(OSE)\n            if \"F1\" in self.figure:\n                self.MOSE = np.around(max(LS.T[0] * 0.25), 3)\n                self.k = np.argmax(LS.T[0] * 0.25)\n                self.j = LS.T[1][self.k].astype(int)\n                self.cell = str(int(self.index[self.k]))\n            elif \"F2\" in self.figure:\n                self.fD = np.vstack((np.asarray(self.D.N), LS.T[0]))\n                self.MOSE = MOSE\n                self.LS = LS.T[0]\n                self.k = np.argmax(OSE)\n        else:\n            MOSE = max(np.multiply(self.N, \n                [max([abs(self.RB[i][j][0][1] - self.RA[i][0][1]) for j in self.range]) for i in self.index]))\n        return np.transpose([[self.RA[i][j] for j in [0, 2]] for i in self.index]), MOSE\n    \n    def noise(self, θseθ, χ):\n        ''' \n        Add Noise to Statistics \n        '''\n        NN = np.asarray(self.D.N).astype(float)\n        S = NN * self.ϵ\n        noise = lambda x: x * math.sqrt(2)\n        \n        nθ = [i[1] for i in θseθ[0]] + χ * noise(self.ω()) / S\n        sen = np.square(θseθ[1]) + 2 * np.square(χ / S)\n        senθ = np.sqrt(sen.astype(float))\n        nsenθ = senθ + χ * noise(self.ω()) / S\n        nsenθ = np.asarray([\"Sample Size Too Small\" if i==np.inf else i for i in nsenθ])\n        nN = self.D.N * (1 + noise(self.ω()) / S)\n        return nθ, nsenθ, nN\n    \n    def __call__(self):\n        ''' \n        Release Noise Infused Statistics \n        '''\n        m1, m2 = self.LSR()\n        nθ, nsenθ, nN = self.noise(m1, m2)\n        return nθ, nsenθ, nN\n    \n    def plot(self, I=None, O=None):\n        fig, ax = plt.subplots(figsize = (8,6))\n        if \"F1\" in self.figure:\n            self.LSR()\n            # Relevant Data\n            fD = np.vstack((self.D.X[self.k], self.D.Y[self.k]))\n            fo = np.vstack((self.Outlier[self.j][0], self.Outlier[self.j][1]))\n            fLA = lambda λ: self.RA[self.k][0][1]*λ + self.RA[self.k][0][0]\n            fLB = lambda λ: self.RB[self.k][self.j][0][1]*λ + self.RB[self.k][self.j][0][0]\n            \n            # Figure 1 - Effect of Outlier on Regression + MOSE line\n            ax.scatter(fD[0], fD[1])\n            ax.scatter(fo[0], fo[1])\n            l = np.linspace(0, 1, 5)\n            ax.plot(l, fLA(l), label=\"%s-Estimate in Actual Data\"%self.method)\n            ax.plot(l, fLB(l), linestyle = 'dashed', label=\"%s-Estimate with Outlier\"%self.method)\n            # LS line at 25th pctile\n            p25 = [0.25, 0.25]\n            yp25 = [fLA(p25[0]), fLB(p25[1])]\n            ax.plot(p25, yp25, color='black')\n            \n            ax.set_title(\"FIGURE 1: Calculation of Local Sensitivity $= %s$\"%str(self.MOSE), pad=35)\n            ax.set_ylabel(\"Child's Income Rank for Tract %s\"%self.cell)\n            ax.set_xlabel(\"Parent's Income Rank for Tract %s\"%self.cell)\n            \n            plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=2, mode=\"expand\", borderaxespad=0.)\n            ax.set_xlim(-0.025, 1.025)\n            ax.set_ylim(-0.025, 1.025)\n            \n        if \"F2\" in self.figure:\n            self.LSR()\n            fLA = lambda λ: self.MOSE / λ\n            ax.scatter(self.fD[0], self.fD[1])\n            xmin = min(self.D.N)\n            xmax = max(self.D.N)\n            l = [xmin, xmax]\n            ax.plot(l, fLA(l), label=\"$MOSE = χ\\,/\\,N = %s\\,/\\,N $\"%str(np.around(self.MOSE, 2)), color='black')\n            ax.scatter(self.fD[0][self.k], self.fD[1][self.k], label=\"Tract %d\"%self.k)\n            ax.set_title(\"FIGURE 2: Maximum Observed Sensitivity Envelope for %s\"%self.method, pad=35)\n            ax.set_ylabel(\"Local Sensitivity of $̂β_1$ Estimates\")\n            ax.set_xlabel(\"Number of Individuals in Tract\")\n            \n            ax.set_xscale('log')\n            ax.set_yscale('log')\n            \n            ax.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=2, mode=\"expand\", borderaxespad=0.)\n            ax.set_xlim(xmin *0.9, xmax * 1.1)\n            ax.set_ylim(min(self.LS)*0.9, self.MOSE/(xmin *0.9))\n            \n        if \"F3\" in self.figure:\n            # Figure 3\n            l = np.linspace(0, 1, 5)\n            if O is not None:\n                ax.scatter(self.Outlier[O][0], self.Outlier[O][1])\n                ao, bo = self.lsR(I, O)\n                if self.method == \"OLS\":\n                    co, do, eo = self.lstsq(ao, bo)\n                if self.method == \"MM\":\n                    co, do, eo, fo = self.MM(I, O)\n                if self.method == \"LmRob\":\n                    co, do, eo, fo = self.lmrob(ao, bo)\n                lineo = lambda x: co[1]*x + co[0]\n                ax.plot(l, lineo(l))\n            ax.scatter(self.D.X[I], self.D.Y[I])\n            a, b = self.lsR(I)\n            if self.method == \"OLS\":\n                c, d, e = self.lstsq(a, b)\n            if self.method == \"MM\":\n                c, d, e, f = self.MM(I)\n            if self.method == \"LmRob\":\n                c, d, e, f = self.lmrob(a, b)\n            line = lambda x: c[1]*x + c[0]\n            ax.plot(l, line(l))\n            ax.set_xlim(-0.025, 1.025)\n            ax.set_ylim(-0.025, 1.025)\n\n        ax.grid(which='minor', color='w', alpha=0.3)\n        plt.show()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "varInspector": {
      "window_display": false,
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "library": "var_list.py",
          "delete_cmd_prefix": "del ",
          "delete_cmd_postfix": "",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "library": "var_list.r",
          "delete_cmd_prefix": "rm(",
          "delete_cmd_postfix": ") ",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ]
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}